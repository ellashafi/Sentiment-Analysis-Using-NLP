{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a559bd-8aac-4b06-8691-59611baaee05",
   "metadata": {},
   "source": [
    "In this notebook, we collect 5000 posts from two subreddits of Breaking Bad and Better Call Saul Series, using API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98443bfe-1241-4c48-a86d-730a472ce8b2",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6b54b42-348f-4b64-85d4-c8eb04550221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb9b323",
   "metadata": {},
   "source": [
    "# Scrape Data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf34b0-2869-483d-b5f5-0937f4cee19b",
   "metadata": {},
   "source": [
    "Below functions exports submissions from reddit for the chosen subreddits and then convert them into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84b56000-0144-469f-a859-3960ef37dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_subreddit(subreddit, subreddit_type, size, page_size = 500):\n",
    "    assert subreddit_type in ('submission', 'comment')\n",
    "    url = f\"https://api.pushshift.io/reddit/search/{subreddit_type}\"\n",
    "    final_list = []\n",
    "    for i in range(math.ceil(size / page_size)): \n",
    "        print(f'Downloading {page_size} out of {size} posts, number {i+1}')\n",
    "        if i == 0:\n",
    "            params = {\n",
    "                'subreddit': subreddit, \n",
    "                'size': page_size\n",
    "            }\n",
    "        else:\n",
    "            params = {\n",
    "            'subreddit': subreddit, \n",
    "            'size': page_size,\n",
    "            'before': last_time\n",
    "            }\n",
    "\n",
    "        res = requests.get(url, params)\n",
    "        assert res.status_code == 200\n",
    "        data = res.json()\n",
    "        post_list = data['data']\n",
    "        last_time = post_list[-1]['created_utc']\n",
    "        final_list.extend(post_list)\n",
    "        time.sleep(2)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c1aa4ac-cbe0-4388-8cba-218024678448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reddit_df(reddit_list): \n",
    "    df = pd.DataFrame(reddit_list)\n",
    "    df = df[['subreddit', 'selftext', 'title']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16e9d72e-9d15-4d42-bf36-72049c359f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 500 out of 2500 posts, number 1\n",
      "Downloading 500 out of 2500 posts, number 2\n",
      "Downloading 500 out of 2500 posts, number 3\n",
      "Downloading 500 out of 2500 posts, number 4\n",
      "Downloading 500 out of 2500 posts, number 5\n"
     ]
    }
   ],
   "source": [
    "# Breaking Bad Subreddit:\n",
    "bb_submission_list = get_subreddit('breakingbad', 'submission', 2500, page_size = 500)\n",
    "bb_submission_df =  make_reddit_df(bb_submission_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6344195e-78db-448e-9d53-e4669f5b6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breakingbad</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>If only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breakingbad</td>\n",
       "      <td>Ok so the show itself is a “scary” and violent...</td>\n",
       "      <td>I’m squeamish/gets scared easily - anyone wann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>breakingbad</td>\n",
       "      <td>If Hank simply watched security footage from t...</td>\n",
       "      <td>Motels didn't have cameras back then?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>breakingbad</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Walter Jr outfit in this scene:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>breakingbad</td>\n",
       "      <td>You can’t get near him and have to lay low. Wh...</td>\n",
       "      <td>If you were Walt and the store was out of Etch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                           selftext  \\\n",
       "0  breakingbad                                          [removed]   \n",
       "1  breakingbad  Ok so the show itself is a “scary” and violent...   \n",
       "2  breakingbad  If Hank simply watched security footage from t...   \n",
       "3  breakingbad                                          [removed]   \n",
       "4  breakingbad  You can’t get near him and have to lay low. Wh...   \n",
       "\n",
       "                                               title  \n",
       "0                                            If only  \n",
       "1  I’m squeamish/gets scared easily - anyone wann...  \n",
       "2              Motels didn't have cameras back then?  \n",
       "3                    Walter Jr outfit in this scene:  \n",
       "4  If you were Walt and the store was out of Etch...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "252f365e-a32c-46d6-ae30-5d160128508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 500 out of 2500 posts, number 1\n",
      "Downloading 500 out of 2500 posts, number 2\n",
      "Downloading 500 out of 2500 posts, number 3\n",
      "Downloading 500 out of 2500 posts, number 4\n",
      "Downloading 500 out of 2500 posts, number 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2496, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better Call Saul Subreddit:\n",
    "bcs_submission_list = get_subreddit('betterCallSaul', 'submission', 2500, page_size = 500)\n",
    "bcs_submission_df =  make_reddit_df(bcs_submission_list)\n",
    "bcs_submission_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c63205-4c0b-48e6-95d7-dc18633a607f",
   "metadata": {},
   "source": [
    "Now we save the data frames into csv format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "300fa376-0b0b-4fa8-abcb-9585c35057f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcs_submission_df.to_csv('data/bettercallsaul.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a38cbd25-9f01-4054-b39e-5df930bdc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_submission_df.to_csv('data/breakingbad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "12a5433c-c8f2-46d2-bf81-8d9150812f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_df = pd.concat([bcs_submission_df, bb_submission_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bbb97c12-3842-459d-80c2-608bcb58ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_df.to_csv('data/subreddits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37de2b-08e5-49fc-9b6e-bfa0d1d6bff9",
   "metadata": {},
   "source": [
    "Next, we perform NLP and EDA on gathered data (notebook 2.NPL-EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ec7f4-690e-4bd1-a513-88684fd445d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e4ee545c5f92b906b67408868d5c4fa102e2be9ab37f5a84f119d93af15ade1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
